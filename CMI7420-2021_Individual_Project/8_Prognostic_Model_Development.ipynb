{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971f8df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pickle import dump\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras_tuner import BayesianOptimization, Objective\n",
    "from tensorflow.keras import callbacks, models\n",
    "\n",
    "from progtools.preprocessing import RawFlightData, DataStructure\n",
    "from progtools.modelling import gpu_check, RemainingUsefulLifeHyperModel\n",
    "from progtools.scoring import rul_scoring\n",
    "from progtools.visuals import unit_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e4faf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that TensorFlow is able to detect the GPU\n",
    "gpu_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e319ee6",
   "metadata": {},
   "source": [
    "# Import, split and scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf144c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the raw flight data in\n",
    "filename = \"data/N-CMAPSS_DS05.h5\"\n",
    "raw_data_read = RawFlightData(filename=filename)\n",
    "\n",
    "#create the development dataframes\n",
    "df_W_dev = raw_data_read.dev_flight_data()\n",
    "df_X_s_dev = raw_data_read.dev_sensor_data()\n",
    "df_A_dev = raw_data_read.dev_aux_data()\n",
    "df_Y_dev = raw_data_read.dev_RUL_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461e0b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#downsample for faster model iteration\n",
    "sample_index = np.arange(1,max(df_A_dev.index),10)\n",
    "\n",
    "df_A_dev = df_A_dev.loc[sample_index]\n",
    "df_W_dev = df_W_dev.loc[sample_index]\n",
    "df_X_s_dev = df_X_s_dev.loc[sample_index]\n",
    "df_Y_dev = df_Y_dev.loc[sample_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b26d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#join the scenario descriptors with the physical sensors to be included in the model\n",
    "df_X=pd.concat([df_X_s_dev[[\"Wf\",\"T24\",\"T30\",\"T48\",\"T50\",\"P24\",\"Ps30\",\"P40\",\"P50\"]], df_W_dev],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438acdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split out the input training and validation datasets\n",
    "df_X_train = df_X[df_A_dev[\"unit\"]<=5]\n",
    "df_X_val = df_X[df_A_dev[\"unit\"]>5]\n",
    "\n",
    "df_Y_train = df_Y_dev[df_A_dev[\"unit\"]<=5]\n",
    "df_Y_val = df_Y_dev[df_A_dev[\"unit\"]>5]\n",
    "\n",
    "df_A_train = df_A_dev[df_A_dev[\"unit\"]<=5]\n",
    "df_A_val = df_A_dev[df_A_dev[\"unit\"]>5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b6e3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a scaler\n",
    "X_scaler = MinMaxScaler().fit(np.asarray(df_X_train))\n",
    "\n",
    "#store the scaler\n",
    "dump(X_scaler, open(\"prognostic_models/9_Parameter_Prognostic_Scaler.pkl\",\"wb\"))\n",
    "\n",
    "#scale the training and validation inputs\n",
    "X_train_scaled = X_scaler.transform(np.asarray(df_X_train))\n",
    "X_val_scaled = X_scaler.transform(np.asarray(df_X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d348546a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrangle back into dataframes for structuring\n",
    "df_X_train = pd.DataFrame(data=X_train_scaled,\n",
    "                          index=df_X_train.index,\n",
    "                          columns=df_X_train.columns)\n",
    "\n",
    "df_X_val = pd.DataFrame(data=X_val_scaled,\n",
    "                        index=df_X_val.index,\n",
    "                        columns=df_X_val.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d581c2",
   "metadata": {},
   "source": [
    "# Structure the Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5363f424",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = DataStructure(df_X_train,\n",
    "                            df_Y_train,\n",
    "                            df_A_train)\n",
    "\n",
    "df_validation = DataStructure(df_X_val,\n",
    "                              df_Y_val,\n",
    "                              df_A_val)\n",
    "\n",
    "X_train = df_training.create_X(2000)\n",
    "y_train = np.asarray(df_training.create_y(piece_wise=True)[\"RUL\"])\n",
    "\n",
    "X_val = df_validation.create_X(2000)\n",
    "y_val = np.asarray(df_validation.create_y(piece_wise=True)[\"RUL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6249cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation data is expected as a tuple\n",
    "validation_data = (X_val, y_val)\n",
    "\n",
    "#print out results to check all shapes match up\n",
    "print(f\"Training Predictor Data Shape:{np.shape(X_train)}\")\n",
    "print(f\"Training Target Data Shape: {np.shape(y_train)}\")\n",
    "print(f\"Validation Predictor Data Shape: {np.shape(X_val)}\")\n",
    "print(f\"Validation Target Data Shape: {np.shape(y_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9e081d",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5c6b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure a Bayesian Optimizer Tuner\n",
    "hyper_model_search = BayesianOptimization(RemainingUsefulLifeHyperModel(features=13),\n",
    "                                          objective=Objective(\"val_mse\",\n",
    "                                                              direction=\"min\"),\n",
    "                                          max_trials=400,\n",
    "                                          seed=42,\n",
    "                                          directory=\"pronostics_searches\",\n",
    "                                          project_name=\"9_parameter_ver0\",\n",
    "                                          overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68ee52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an early stopping callback\n",
    "callback = callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "                                   patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1293eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#run the hyper-parameter optimisaiton and using the validaiton tuple as a hold out\n",
    "hyper_model_search.search(X_train,\n",
    "                          y_train,\n",
    "                          validation_data=validation_data,\n",
    "                          callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c674f516",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the best model from the grid search as \"best_model\"\n",
    "best_model = hyper_model_search.get_best_models(num_models=1)[0]\n",
    "\n",
    "#save the best model for use later\n",
    "best_model.save(\"prognostic_models/9_Parameter_Prognostic_Model.h5\")\n",
    "\n",
    "#display the summary of each layer of the best model\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5090fa5b",
   "metadata": {},
   "source": [
    "# Training Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23fbb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create predictions against the training data\n",
    "try:\n",
    "    y_train_pred = best_model.predict(X_train)\n",
    "except(NameError):\n",
    "    best_model = models.load_model(\"prognostic_models/9_Parameter_Prognostic_Model.h5\")\n",
    "    y_train_pred = best_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b8562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#examine the results of the training predictions against the training ground-truth [the piece-wise target]\n",
    "rul_scoring(y_train,y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5025f7",
   "metadata": {},
   "source": [
    "# Validation Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1775ad47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create predictions agains the validation data\n",
    "y_val_pred = best_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7c2345",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exmaine the results of the validation predictions against the validation ground-truth [the piece-wise target]\n",
    "rul_scoring(y_val,y_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab43a25",
   "metadata": {},
   "source": [
    "# Individual Unit Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df129cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe joining the piece-wise target, with the predictions for the training data\n",
    "df_train_results=df_training.create_y().join(pd.DataFrame(y_train_pred, columns=[\"yhat\"]))\n",
    "\n",
    "#calculate the square of the difference between prediction and groun-truth to calculate individual RMSE scores by unit\n",
    "df_train_results[\"delta_sq\"]=(df_train_results[\"RUL\"]-df_train_results[\"yhat\"])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923a3222",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe joining the piece-wise target, with the predictions for the validation data\n",
    "df_val_results=df_validation.create_y().join(pd.DataFrame(y_val_pred, columns=[\"yhat\"]))\n",
    "\n",
    "#calculate the square of the difference between prediction and groun-truth to calculate individual RMSE scores by unit\n",
    "df_val_results[\"delta_sq\"]=(df_val_results[\"RUL\"]-df_val_results[\"yhat\"])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad18876",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate the results into a single dataframe\n",
    "df_results = pd.concat([df_train_results,df_val_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fcabe0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plot out ground-truth versus prediction with RMSE by unit\n",
    "unit_plots(df_results,title=\"9-Parameter Model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
